# **LinearRAG: Linear Graph Retrieval-Augmented Generation on Large-scale Corpora**

> A relation-free graph construction method for efficient GraphRAG. It eliminates LLM token costs during graph construction, making GraphRAG faster and more efficient than ever.

<p align="center">
  <a href="https://arxiv.org/abs/2510.10114" target="_blank">
    <img src="https://img.shields.io/badge/Paper-Arxiv-red?logo=arxiv&style=flat-square" alt="arXiv:2506.08938">
  </a>
  <a href="https://huggingface.co/datasets/Zly0523/linear-rag/tree/main" target="_blank">
    <img src="https://img.shields.io/badge/HuggingFace-Model-yellow?logo=huggingface&style=flat-square" alt="HuggingFace">
  </a>
  <a href="https://github.com/LuyaoZhuang/linear-rag" target="_blank">
    <img src="https://img.shields.io/badge/GitHub-Project-181717?logo=github&style=flat-square" alt="GitHub">
  </a>
</p>

---

## ğŸš€ **Highlights**

- âœ… **Context-Preserving**: Relation-free graph construction, relying on lightweight entity recognition and semantic linking to achieve comprehensive contextual comprehension.
- âœ… **Complex Reasoning**: Enables deep retrieval via semantic bridging, achieving multi-hop reasoning in a single retrieval pass without requiring explicit relational graphs.
- âœ… **High Scalability**: Zero LLM token consumption, faster processing speed, and linear time/space complexity.

<p align="center">
  <img src="figure/main_figure.png" width="95%" alt="Framework Overview">
</p>

---

## ğŸ‰ **News**

- **[2025-10-27]** We release **[LinearRAG](https://github.com/DEEP-PolyU/LinearRAG)**, a relation-free graph construction method for efficient GraphRAG.
- **[2025-06-06]** We release **[GraphRAG-Bench](https://github.com/GraphRAG-Bench/GraphRAG-Benchmark.git)**, the benchmark for evaluating GraphRAG models.
- **[2025-01-21]** We release the **[GraphRAG survey](https://github.com/DEEP-PolyU/Awesome-GraphRAG)**.

---

## ğŸ› ï¸ **Usage**

### 1ï¸âƒ£ Install Dependencies

**Step 1: Install Python packages**

```bash
pip install -r requirements.txt
```

**Step 2: Download Spacy language model**

```bash
python -m spacy download en_core_web_trf
```

> **Note:** For the `medical` dataset, you need to install the scientific/biomedical Spacy model:

```bash
pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.3/en_core_sci_scibert-0.5.3.tar.gz
```

**Step 3: Set up your OpenAI API key**

```bash
export OPENAI_API_KEY="your-api-key-here"
export OPENAI_BASE_URL="your-base-url-here"
```

**Optional: Configure Model Client (multi-backend)**

```bash
# Provider selection: openai (default) / mock (offline)
export LLM_PROVIDER="openai"

# Retry & timeout
export LLM_TIMEOUT_S="60"
export LLM_MAX_RETRIES="3"
export LLM_RETRY_BACKOFF_S="0.5"
```

ç¦»çº¿éªŒè¯ï¼ˆä¸è®¿é—®ç½‘ç»œï¼‰å¯ä»¥ä½¿ç”¨ï¼š

```bash
export LLM_PROVIDER="mock"
python scripts/validate_model_client_mock.py
```

**Step 4: Download Datasets**

Download the datasets from HuggingFace and place them in the `dataset/` folder:

```bash
git clone https://huggingface.co/datasets/Zly0523/linear-rag
cp -r linear-rag/dataset/* dataset/
```

**Step 5: Prepare Embedding Model**

Make sure the embedding model is available at:

```
model/all-mpnet-base-v2/
```

### 2ï¸âƒ£ Quick Start Example

```bash
SPACY_MODEL="en_core_web_trf"
EMBEDDING_MODEL="model/all-mpnet-base-v2"
DATASET_NAME="2wikimultihop"
LLM_MODEL="gpt-4o-mini"
MAX_WORKERS=16

python run.py \
    --spacy_model ${SPACY_MODEL} \
    --embedding_model ${EMBEDDING_MODEL} \
    --dataset_name ${DATASET_NAME} \
    --llm_model ${LLM_MODEL} \
    --max_workers ${MAX_WORKERS}
```

### 3ï¸âƒ£ FastAPI æœåŠ¡

å¯åŠ¨æœåŠ¡ï¼ˆé»˜è®¤ 8000 ç«¯å£ï¼‰ï¼š

```bash
uvicorn src.api_server:app --host 0.0.0.0 --port 8000
```

ç¤ºä¾‹è¯·æ±‚ï¼š

- ç´¢å¼•æ„å»ºï¼š

```bash
curl -X POST http://localhost:8000/index \
  -H "Content-Type: application/json" \
  -d '{
    "dataset_name": "medical",
    "embedding_model": "model/all-mpnet-base-v2",
    "spacy_model": "en_core_web_trf",
    "working_dir": "./import"
  }'
```

- é—®ç­”ï¼ˆéœ€å…ˆå®Œæˆç´¢å¼•ï¼‰ï¼š

```bash
curl -X POST http://localhost:8000/qa \
  -H "Content-Type: application/json" \
  -d '{
    "dataset_name": "medical",
    "questions": [
      {"question": "Who discovered X?", "answer": "Example answer"}
    ]
  }'
```

- è¯„æµ‹ï¼ˆåŸºäºé¢„æµ‹ç»“æœè·¯å¾„ï¼‰ï¼š

```bash
curl -X POST http://localhost:8000/evaluate \
  -H "Content-Type: application/json" \
  -d '{
    "dataset_name": "medical",
    "predictions_path": "results/medical/<timestamp>/predictions.json"
  }'
```

> æé†’ï¼šéœ€è¦æå‰è®¾ç½® `OPENAI_API_KEY`ï¼ˆå¯é€‰ `OPENAI_BASE_URL`ï¼‰ï¼Œå¹¶ç¡®ä¿ SentenceTransformer ä¸ spaCy æ¨¡å‹å·²ä¸‹è½½åˆ°å¯¹åº”ç›®å½•ã€‚

#### MinerU æ–‡æ¡£è§£æ

```bash
export MINERU_BASE_URL="http://127.0.0.1:8000"   # å¯é€‰ï¼Œé»˜è®¤å³æ­¤åœ°å€
export MINERU_FILE_PARSE_PATH="/file_parse"       # å¯é€‰ï¼Œé»˜è®¤å³æ­¤è·¯å¾„

curl -X POST http://localhost:8000/mineru/parse \
  -H "Content-Type: application/json" \
  -d '{
    "file_path": "data/example.pdf",
    "backend": "pipeline",
    "parse_method": "pipeline",
    "return_md": true,
    "return_images": true
  }'
```

è¿”å›å°†åŒ…å« MinerU è°ƒç”¨çŠ¶æ€åŠè½ç›˜è·¯å¾„ã€‚é»˜è®¤è¾“å‡ºç›®å½• `results/mineru/<æ–‡ä»¶å>/<timestamp>/`ï¼Œå¯é€šè¿‡è¯·æ±‚ä½“ `output_dir` è¦†ç›–ã€‚
è‹¥ MinerU ä¸ FastAPI ä¸åŒç«¯å£ï¼ˆFastAPI é»˜è®¤ 8000ï¼ŒMinerU ä¹Ÿå¸¸ç”¨ 8000ï¼‰ï¼Œéœ€å°† `MINERU_BASE_URL` è®¾ç½®ä¸º MinerU å®é™…åœ°å€æˆ–è°ƒæ•´ FastAPI ç«¯å£ï¼Œå¦åˆ™å¯èƒ½æ”¶åˆ° `detail: Not Found`ï¼›è‹¥ MinerU æš´éœ²çš„è·¯å¾„ä¸åŒï¼Œå¯é€šè¿‡ `MINERU_FILE_PARSE_PATH` ä¿®æ”¹ã€‚

#### æ€ç»´å¯¼å›¾ç”Ÿæˆ

æ ¹æ® MinerU ç”Ÿæˆçš„ Markdown ç»“æ„åŒ–ä¸ºæ ‘çŠ¶ JSONï¼ˆæ ¹èŠ‚ç‚¹ä¸ºæ–‡ä»¶åï¼ŒèŠ‚ç‚¹åŒ…å« `id/level/title/content/order`ï¼‰ã€‚
é»˜è®¤ä»…ä¿ç•™ä» **Introduction** å¼€å§‹åˆ° **Conclusion** ç»“æŸï¼ˆåŒ…å«ä¸¤ç«¯ï¼‰çš„æ¨¡å—èŒƒå›´åŠå…¶å…¨éƒ¨å­æ ‘ï¼›è‹¥æ— æ³•å®šä½ Introduction æˆ– Conclusionï¼Œåˆ™é€€åŒ–ä¸ºåˆ é™¤ `Abstract/æ‘˜è¦`ã€`References/å‚è€ƒæ–‡çŒ®` åŠæ‰€æœ‰å°¾éƒ¨ç« èŠ‚ï¼ˆå¦‚ `Acknowledgements/è‡´è°¢`ã€`Appendix/é™„å½•`ï¼‰åŠå…¶å­æ ‘ã€‚

```bash
curl -X POST http://localhost:8000/mindmap \
  -H "Content-Type: application/json" \
  -d '{
    "doc_name": "sustainability-16-02641-v2"
  }'
```

æœåŠ¡ä¼šåœ¨ `output/mineru/<doc_name>/` ä¸‹é€‰å–æ—¶é—´æˆ³ç›®å½•åæœ€å¤§çš„è®°å½•ï¼Œè¯»å– `<doc_name>/<doc_name>.md`ï¼Œå¹¶è¿”å›æ€ç»´å¯¼å›¾æ ‘ã€‚

#### æ€ç»´å¯¼å›¾æ¨¡å—è§£é‡Šï¼ˆå¹¶å‘ã€éæµå¼ï¼‰

å¯¹æ€ç»´å¯¼å›¾æ ‘é™¤æ ¹èŠ‚ç‚¹å¤–çš„æ¯ä¸ªæ¨¡å—ï¼šç”¨â€œæ¨¡å—æ ‡é¢˜ + æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ + æ¨¡å—æç¤ºè¯â€å¹¶å‘è°ƒç”¨å¤§æ¨¡å‹ï¼Œè¿”å›æ¯ä¸ªæ¨¡å—çš„è§£é‡Šå†…å®¹ï¼ˆå•æ¨¡å—ä¸åšæµå¼è¾“å‡ºï¼‰ã€‚
è§£é‡ŠèŒƒå›´ä¸ `/mindmap` ä¸€è‡´ï¼ˆIntroductionâ†’Conclusionï¼›æˆ–é€€åŒ–åˆ é™¤ Abstract/References/å°¾éƒ¨ç« èŠ‚ï¼‰ï¼Œå¹¶ä¸”è§£é‡Šè¾“å…¥ä¸ºâ€œè¯¥æ¨¡å—å­æ ‘å†…å®¹ + å­æ ‘æ£€ç´¢ä¸Šä¸‹æ–‡â€ã€‚
è§£é‡Šå®Œæˆåä¼šåŸºäºåŒä¸€ä»½ `root` æ ‘ï¼ˆèŠ‚ç‚¹å« `llm_answer`ï¼‰é¢å¤–ç”Ÿæˆä¸€ä»½ä»…åŒ…å«â€œæ ‡é¢˜ + llm_answerâ€çš„ Markdownï¼Œå¹¶è½ç›˜åˆ° `results/<dataset_name>/<timestamp>/mindmap_explain.md`ï¼ŒåŒæ—¶åœ¨å“åº”ä¸­è¿”å› `explain_markdown` ä¸ `explain_markdown_path`ã€‚

å‰ç½®æ¡ä»¶ï¼š
- å·²ç”Ÿæˆ `dataset/<doc_name>/chunks.json`ï¼ˆå¯é€šè¿‡ `/markdown/chunk` ç”Ÿæˆï¼‰
- å·²è°ƒç”¨ `/index` å®Œæˆç´¢å¼•æ„å»ºï¼ˆ`dataset_name` éœ€ä¸ `doc_name` ä¸€è‡´ï¼Œæˆ–åœ¨è¯·æ±‚ä¸­æŒ‡å®š `dataset_name`ï¼‰

```bash
curl -X POST http://localhost:8000/mindmap/explain \
  -H "Content-Type: application/json" \
  -d '{
    "doc_name": "sustainability-16-02641-v2",
    "module_max_workers": 8,
    "retrieval_top_k": 5,
    "include_tree": true,
    "include_context": true
  }'
```

#### content_list è½¬ chunk

å°† MinerU çš„ `_content_list.json` è½¬ä¸ºæ ‡å‡†åˆ†å—æ–‡ä»¶ `data/<doc_name>/chunk.json`ã€‚

```bash
curl -X POST http://localhost:8000/content/chunk \
  -H "Content-Type: application/json" \
  -d '{
    "doc_name": "sustainability-16-02641-v2"
  }'
```

æœåŠ¡ä¼šåœ¨ `output/mineru/<doc_name>/` ä¸‹é€‰å–æ—¶é—´æˆ³ç›®å½•åæœ€å¤§çš„ç›®å½•ï¼Œè¯»å– `<doc_name>_content_list.json`ï¼ŒæŒ‰é…ç½®çš„ `chunk_token_size` ä¸ `chunk_overlap_token_size` ç”Ÿæˆåˆ†å—å¹¶å†™å…¥ `data/<doc_name>/chunk.json`ã€‚

#### Markdown è½¬ chunk

å°† MinerU ç”Ÿæˆçš„ Markdown ç›´æ¥åˆ†å—å†™å…¥ `dataset/<doc_name>/chunks.json`ã€‚

```bash
curl -X POST http://localhost:8000/markdown/chunk \
  -H "Content-Type: application/json" \
  -d '{
    "doc_name": "2021å¹´ç‚¹äº‘å§¿æ€ä¼°è®¡"
  }'
```

æœåŠ¡ä¼šåœ¨ `output/mineru/<doc_name>/` ä¸‹é€‰å–æ—¶é—´æˆ³ç›®å½•åæœ€å¤§çš„ç›®å½•ï¼Œè¯»å– `<doc_name>/<doc_name>.md`ï¼ŒæŒ‰é…ç½®çš„ `chunk_token_size` ä¸ `chunk_overlap_token_size` ç©ºæ ¼åˆ†è¯ç”Ÿæˆåˆ†å—ã€‚

## ğŸ¯ **Performance**

<div align="center">
<img src="figure/generation_results.png" alt="framework" width="1000">

**Main results of end-to-end performance**

</div>
<div align="center">
<img src="figure/efficiency_result.png" alt="framework" width="1000">




![framework](figure/efficiency_result.png)

![framework](figure/efficiency_result.png)

**Efficiency and performance comparison.**

</div>

## ğŸ“– Citation

If you find this work helpful, please consider citing us:

```bibtex
@article{zhuang2025linearrag,
  title={LinearRAG: Linear Graph Retrieval Augmented Generation on Large-scale Corpora},
  author={Zhuang, Luyao and Chen, Shengyuan and Xiao, Yilin and Zhou, Huachi and Zhang, Yujing and Chen, Hao and Zhang, Qinggang and Huang, Xiao},
  journal={arXiv preprint arXiv:2510.10114},
  year={2025}
}
```

This project is licensed under the GNU General Public License v3.0 ([License](LICENSE.TXT)).

## ğŸ“¬ Contact

âœ‰ï¸ Email: zhuangluyao523@gmail.com
