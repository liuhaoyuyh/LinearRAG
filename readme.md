# **LinearRAG: Linear Graph Retrieval-Augmented Generation on Large-scale Corpora**

> A relation-free graph construction method for efficient GraphRAG. It eliminates LLM token costs during graph construction, making GraphRAG faster and more efficient than ever.

<p align="center">
  <a href="https://arxiv.org/abs/2510.10114" target="_blank">
    <img src="https://img.shields.io/badge/Paper-Arxiv-red?logo=arxiv&style=flat-square" alt="arXiv:2506.08938">
  </a>
  <a href="https://huggingface.co/datasets/Zly0523/linear-rag/tree/main" target="_blank">
    <img src="https://img.shields.io/badge/HuggingFace-Model-yellow?logo=huggingface&style=flat-square" alt="HuggingFace">
  </a>
  <a href="https://github.com/LuyaoZhuang/linear-rag" target="_blank">
    <img src="https://img.shields.io/badge/GitHub-Project-181717?logo=github&style=flat-square" alt="GitHub">
  </a>
</p>

---

## ğŸš€ **Highlights**

- âœ… **Context-Preserving**: Relation-free graph construction, relying on lightweight entity recognition and semantic linking to achieve comprehensive contextual comprehension.
- âœ… **Complex Reasoning**: Enables deep retrieval via semantic bridging, achieving multi-hop reasoning in a single retrieval pass without requiring explicit relational graphs.
- âœ… **High Scalability**: Zero LLM token consumption, faster processing speed, and linear time/space complexity.

<p align="center">
  <img src="figure/main_figure.png" width="95%" alt="Framework Overview">
</p>

---

## ğŸ‰ **News**

- **[2025-10-27]** We release **[LinearRAG](https://github.com/DEEP-PolyU/LinearRAG)**, a relation-free graph construction method for efficient GraphRAG.
- **[2025-06-06]** We release **[GraphRAG-Bench](https://github.com/GraphRAG-Bench/GraphRAG-Benchmark.git)**, the benchmark for evaluating GraphRAG models.
- **[2025-01-21]** We release the **[GraphRAG survey](https://github.com/DEEP-PolyU/Awesome-GraphRAG)**.

---

## ğŸ› ï¸ **Usage**

### 1ï¸âƒ£ Install Dependencies

**Step 1: Install Python packages**

```bash
pip install -r requirements.txt
```

**Step 2: Download Spacy language model**

```bash
python -m spacy download en_core_web_trf
```

> **Note:** For the `medical` dataset, you need to install the scientific/biomedical Spacy model:

```bash
pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.3/en_core_sci_scibert-0.5.3.tar.gz
```

**Step 3: Set up your OpenAI API key**

```bash
export OPENAI_API_KEY="your-api-key-here"
export OPENAI_BASE_URL="your-base-url-here"
```

**Step 4: Download Datasets**

Download the datasets from HuggingFace and place them in the `dataset/` folder:

```bash
git clone https://huggingface.co/datasets/Zly0523/linear-rag
cp -r linear-rag/dataset/* dataset/
```

**Step 5: Prepare Embedding Model**

Make sure the embedding model is available at:

```
model/all-mpnet-base-v2/
```

### 2ï¸âƒ£ Quick Start Example

```bash
SPACY_MODEL="en_core_web_trf"
EMBEDDING_MODEL="model/all-mpnet-base-v2"
DATASET_NAME="2wikimultihop"
LLM_MODEL="gpt-4o-mini"
MAX_WORKERS=16

python run.py \
    --spacy_model ${SPACY_MODEL} \
    --embedding_model ${EMBEDDING_MODEL} \
    --dataset_name ${DATASET_NAME} \
    --llm_model ${LLM_MODEL} \
    --max_workers ${MAX_WORKERS}
```

### 3ï¸âƒ£ FastAPI æœåŠ¡

å¯åŠ¨æœåŠ¡ï¼ˆé»˜è®¤ 8000 ç«¯å£ï¼‰ï¼š

```bash
uvicorn src.api_server:app --host 0.0.0.0 --port 8000
```

ç¤ºä¾‹è¯·æ±‚ï¼š

- ç´¢å¼•æ„å»ºï¼š

```bash
curl -X POST http://localhost:8000/index \
  -H "Content-Type: application/json" \
  -d '{
    "dataset_name": "medical",
    "embedding_model": "model/all-mpnet-base-v2",
    "spacy_model": "en_core_web_trf",
    "working_dir": "./import"
  }'
```

- é—®ç­”ï¼ˆéœ€å…ˆå®Œæˆç´¢å¼•ï¼‰ï¼š

```bash
curl -X POST http://localhost:8000/qa \
  -H "Content-Type: application/json" \
  -d '{
    "dataset_name": "medical",
    "questions": [
      {"question": "Who discovered X?", "answer": "Example answer"}
    ]
  }'
```

- è¯„æµ‹ï¼ˆåŸºäºé¢„æµ‹ç»“æœè·¯å¾„ï¼‰ï¼š

```bash
curl -X POST http://localhost:8000/evaluate \
  -H "Content-Type: application/json" \
  -d '{
    "dataset_name": "medical",
    "predictions_path": "results/medical/<timestamp>/predictions.json"
  }'
```

> æé†’ï¼šéœ€è¦æå‰è®¾ç½® `OPENAI_API_KEY`ï¼ˆå¯é€‰ `OPENAI_BASE_URL`ï¼‰ï¼Œå¹¶ç¡®ä¿ SentenceTransformer ä¸ spaCy æ¨¡å‹å·²ä¸‹è½½åˆ°å¯¹åº”ç›®å½•ã€‚

#### MinerU æ–‡æ¡£è§£æ

```bash
export MINERU_BASE_URL="http://127.0.0.1:8000"   # å¯é€‰ï¼Œé»˜è®¤å³æ­¤åœ°å€
export MINERU_FILE_PARSE_PATH="/file_parse"       # å¯é€‰ï¼Œé»˜è®¤å³æ­¤è·¯å¾„

curl -X POST http://localhost:8000/mineru/parse \
  -H "Content-Type: application/json" \
  -d '{
    "file_path": "data/example.pdf",
    "backend": "pipeline",
    "parse_method": "pipeline",
    "return_md": true,
    "return_images": true
  }'
```

è¿”å›å°†åŒ…å« MinerU è°ƒç”¨çŠ¶æ€åŠè½ç›˜è·¯å¾„ã€‚é»˜è®¤è¾“å‡ºç›®å½• `results/mineru/<æ–‡ä»¶å>/<timestamp>/`ï¼Œå¯é€šè¿‡è¯·æ±‚ä½“ `output_dir` è¦†ç›–ã€‚
è‹¥ MinerU ä¸ FastAPI ä¸åŒç«¯å£ï¼ˆFastAPI é»˜è®¤ 8000ï¼ŒMinerU ä¹Ÿå¸¸ç”¨ 8000ï¼‰ï¼Œéœ€å°† `MINERU_BASE_URL` è®¾ç½®ä¸º MinerU å®é™…åœ°å€æˆ–è°ƒæ•´ FastAPI ç«¯å£ï¼Œå¦åˆ™å¯èƒ½æ”¶åˆ° `detail: Not Found`ï¼›è‹¥ MinerU æš´éœ²çš„è·¯å¾„ä¸åŒï¼Œå¯é€šè¿‡ `MINERU_FILE_PARSE_PATH` ä¿®æ”¹ã€‚

#### æ€ç»´å¯¼å›¾ç”Ÿæˆ

æ ¹æ® MinerU ç”Ÿæˆçš„ Markdown ç»“æ„åŒ–ä¸ºæ ‘çŠ¶ JSONï¼ˆæ ¹èŠ‚ç‚¹ä¸ºæ–‡ä»¶åï¼ŒèŠ‚ç‚¹åŒ…å« `id/level/title/content/order`ï¼‰ã€‚

```bash
curl -X POST http://localhost:8000/mindmap \
  -H "Content-Type: application/json" \
  -d '{
    "doc_name": "sustainability-16-02641-v2"
  }'
```

æœåŠ¡ä¼šåœ¨ `output/mineru/<doc_name>/` ä¸‹é€‰å–æ—¶é—´æˆ³ç›®å½•åæœ€å¤§çš„è®°å½•ï¼Œè¯»å– `<doc_name>/<doc_name>.md`ï¼Œå¹¶è¿”å›æ€ç»´å¯¼å›¾æ ‘ã€‚

#### content_list è½¬ chunk

å°† MinerU çš„ `_content_list.json` è½¬ä¸ºæ ‡å‡†åˆ†å—æ–‡ä»¶ `data/<doc_name>/chunk.json`ã€‚

```bash
curl -X POST http://localhost:8000/content/chunk \
  -H "Content-Type: application/json" \
  -d '{
    "doc_name": "sustainability-16-02641-v2"
  }'
```

æœåŠ¡ä¼šåœ¨ `output/mineru/<doc_name>/` ä¸‹é€‰å–æ—¶é—´æˆ³ç›®å½•åæœ€å¤§çš„ç›®å½•ï¼Œè¯»å– `<doc_name>_content_list.json`ï¼ŒæŒ‰é…ç½®çš„ `chunk_token_size` ä¸ `chunk_overlap_token_size` ç”Ÿæˆåˆ†å—å¹¶å†™å…¥ `data/<doc_name>/chunk.json`ã€‚

#### Markdown è½¬ chunk

å°† MinerU ç”Ÿæˆçš„ Markdown ç›´æ¥åˆ†å—å†™å…¥ `data/<doc_name>/chunk.json`ã€‚

```bash
curl -X POST http://localhost:8000/markdown/chunk \
  -H "Content-Type: application/json" \
  -d '{
    "doc_name": "2021å¹´ç‚¹äº‘å§¿æ€ä¼°è®¡"
  }'
```

æœåŠ¡ä¼šåœ¨ `output/mineru/<doc_name>/` ä¸‹é€‰å–æ—¶é—´æˆ³ç›®å½•åæœ€å¤§çš„ç›®å½•ï¼Œè¯»å– `<doc_name>/<doc_name>.md`ï¼ŒæŒ‰é…ç½®çš„ `chunk_token_size` ä¸ `chunk_overlap_token_size` ç©ºæ ¼åˆ†è¯ç”Ÿæˆåˆ†å—ã€‚

## ğŸ¯ **Performance**

<div align="center">
<img src="figure/generation_results.png" alt="framework" width="1000">

**Main results of end-to-end performance**

</div>
<div align="center">
<img src="figure/efficiency_result.png" alt="framework" width="1000">




![framework](figure/efficiency_result.png)

![framework](figure/efficiency_result.png)

**Efficiency and performance comparison.**

</div>

## ğŸ“– Citation

If you find this work helpful, please consider citing us:

```bibtex
@article{zhuang2025linearrag,
  title={LinearRAG: Linear Graph Retrieval Augmented Generation on Large-scale Corpora},
  author={Zhuang, Luyao and Chen, Shengyuan and Xiao, Yilin and Zhou, Huachi and Zhang, Yujing and Chen, Hao and Zhang, Qinggang and Huang, Xiao},
  journal={arXiv preprint arXiv:2510.10114},
  year={2025}
}
```

This project is licensed under the GNU General Public License v3.0 ([License](LICENSE.TXT)).

## ğŸ“¬ Contact

âœ‰ï¸ Email: zhuangluyao523@gmail.com
